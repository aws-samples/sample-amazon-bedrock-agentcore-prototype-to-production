{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378cb9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: strands-agents 0.0.1 does not provide the extra 'litellm'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall -U -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ed3b8",
   "metadata": {},
   "source": [
    "## Creating a simple agent and experimenting locally\n",
    "\n",
    "Let's create a simple agent with \"Weather\" and \"Calculator\" tools.\n",
    "\n",
    "We will use OpenAI model and provide Azure API Key details\n",
    "\n",
    "![deploy](images/outbound_auth_api.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750f63b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing strands_agents_openai.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile strands_agents_openai.py\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator # Import the calculator tool\n",
    "import argparse\n",
    "import json\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import os\n",
    "\n",
    "##Update the below configuration with your Azure API Key details.\n",
    "os.environ[\"AZURE_API_KEY\"] = \"<YOUR_API_KEY>\"\n",
    "os.environ[\"AZURE_API_BASE\"] = \"<YOUR_API_BASE>\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"<YOUR_API_VERSION>\"\n",
    "\n",
    "# Create a custom tool \n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\" Get weather \"\"\" # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "model = \"azure/gpt-4.1-mini\"\n",
    "litellm_model = LiteLLMModel(\n",
    "    model_id=model, params={\"max_tokens\": 32000, \"temperature\": 0.7}\n",
    ")\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    model=litellm_model,\n",
    "    tools=[calculator, weather],\n",
    "    system_prompt=\"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    ")\n",
    "\n",
    "def strands_agent_open_ai(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    response = agent(user_input)\n",
    "    return response.message['content'][0]['text']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    response = strands_agent_open_ai(json.loads(args.payload))\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4fa05",
   "metadata": {},
   "source": [
    "Invoking local agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python strands_agents_openai.py '{\"prompt\": \"What is the weather now?\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5dca2e",
   "metadata": {},
   "source": [
    "## Create a Resource Credential Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore.services.identity import IdentityClient\n",
    "\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "#Configure API Key Provider\n",
    "identity_client = IdentityClient(region=region)\n",
    "\n",
    "api_key_provider = identity_client.create_api_key_credential_provider({\n",
    "    \"name\": \"openai-apikey-provider\",\n",
    "    \"apiKey\": \"<YOUR_API_KEY>\" # Replace it with the API key you obtain from the external application vendor, e.g., OpenAI\n",
    "})\n",
    "print(api_key_provider)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c89d3d",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime and use the Resource Credential Provider\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "\n",
    "- Import the Runtime App with from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "- Initialize the App in our code with app = BedrockAgentCoreApp()\n",
    "- Decorate the invocation function with the @app.entrypoint decorator\n",
    "- Let AgentCoreRuntime control the running of the agent with app.run()\n",
    "- Retrieve the openAI key from the resource credential provider created in the previous step\n",
    "\n",
    "\n",
    "## Strands Agents with OpenAI model\n",
    "Let's start with our Strands Agent using the GPT 4.1 mini model. All the others will work exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile strands_agents_openai.py\n",
    "import asyncio\n",
    "from bedrock_agentcore.identity.auth import requires_access_token, requires_api_key\n",
    "from strands import Agent, tool\n",
    "from strands_tools import calculator \n",
    "import argparse\n",
    "import json\n",
    "from strands.models.litellm import LiteLLMModel\n",
    "import os\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "AZURE_API_KEY_FROM_CREDS_PROVIDER = \"\"\n",
    "\n",
    "\n",
    "@requires_api_key(\n",
    "    provider_name=\"openai-apikey-provider\" # replace with your own credential provider name\n",
    ")\n",
    "async def need_api_key(*, api_key: str):\n",
    "    global AZURE_API_KEY_FROM_CREDS_PROVIDER\n",
    "    print(f'received api key for async func: {api_key}')\n",
    "    AZURE_API_KEY_FROM_CREDS_PROVIDER = api_key\n",
    "\n",
    "# Don't print empty value at module level - will print in entrypoint function\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# API key will be set dynamically in the entrypoint function\n",
    "#Update the below configuration with your Azure API Key details.\n",
    "os.environ[\"AZURE_API_BASE\"] = \"<YOUR_API_BASE>\"\n",
    "os.environ[\"AZURE_API_VERSION\"] = \"<YOUR_API_VERSION>\"\n",
    "\n",
    "# Create a custom tool \n",
    "@tool\n",
    "def weather():\n",
    "    \"\"\" Get weather \"\"\" # Dummy implementation\n",
    "    return \"sunny\"\n",
    "\n",
    "# Global agent variable\n",
    "agent = None\n",
    "\n",
    "@app.entrypoint\n",
    "async def strands_agent_open_ai(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    global AZURE_API_KEY_FROM_CREDS_PROVIDER, agent\n",
    "    \n",
    "    print(f\"Entrypoint called with AZURE_API_KEY_FROM_CREDS_PROVIDER: '{AZURE_API_KEY_FROM_CREDS_PROVIDER}'\")\n",
    "    \n",
    "    # Get API key if not already retrieved\n",
    "    if not AZURE_API_KEY_FROM_CREDS_PROVIDER:\n",
    "        print(\"Attempting to retrieve API key...\")\n",
    "        try:\n",
    "            await need_api_key(api_key=\"\")\n",
    "            print(f\"API key retrieved: '{AZURE_API_KEY_FROM_CREDS_PROVIDER}'\")\n",
    "            os.environ[\"AZURE_API_KEY\"] = AZURE_API_KEY_FROM_CREDS_PROVIDER\n",
    "            print(\"Environment variable AZURE_API_KEY set\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving API key: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(\"API key already available\")\n",
    "    \n",
    "    # Initialize agent after API key is set\n",
    "    if agent is None:\n",
    "        print(\"Initializing agent with API key...\")\n",
    "        model = \"azure/gpt-4.1-mini\"\n",
    "        litellm_model = LiteLLMModel(\n",
    "            model_id=model, params={\"max_tokens\": 32000, \"temperature\": 0.7}\n",
    "        )\n",
    "        \n",
    "        agent = Agent(\n",
    "            model=litellm_model,\n",
    "            tools=[calculator, weather],\n",
    "            system_prompt=\"You're a helpful assistant. You can do simple math calculation, and tell the weather.\"\n",
    "        )\n",
    "        print(\"Agent initialized successfully\")\n",
    "    \n",
    "    user_input = payload.get(\"prompt\")\n",
    "    print(f\"User input: {user_input}\")\n",
    "    \n",
    "    try:\n",
    "        response = agent(user_input)\n",
    "        print(f\"Agent response: {response}\")\n",
    "        return response.message['content'][0]['text']\n",
    "    except Exception as e:\n",
    "        print(f\"Error in agent processing: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7497a14",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "When you use BedrockAgentCoreApp, it automatically:\n",
    "\n",
    "- Creates an HTTP server that listens on the port 8080\n",
    "- Implements the required /invocations endpoint for processing the agent's requirements\n",
    "- Implements the /ping endpoint for health checks (very important for asynchronous agents)\n",
    "- Handles proper content types and response formats\n",
    "- Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427f5694",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The CreateAgentRuntime operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent.\n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e970f",
   "metadata": {},
   "source": [
    "## Configure AgentCore Runtime deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "![deploy](images/configure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa37bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "import boto3\n",
    "import json\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "agent_name=\"strands_agents_openai\"\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    entrypoint=\"strands_agents_openai.py\",\n",
    "    auto_create_execution_role=True,\n",
    "    auto_create_ecr=True,\n",
    "    agent_name=agent_name,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748edd7a",
   "metadata": {},
   "source": [
    "## Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "![deploy](images/launch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7005d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch()\n",
    "launch_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f44aaa",
   "metadata": {},
   "source": [
    "### Add extra required policies to auto-created role\n",
    "\n",
    "Since we are adding some outbound identity to our agent, we will need to get some API Keys and Secrets that are not available in the auto-created role. To do so, we will need to add some extra permissions to our auto-created IAM role. Let's first get this role and then add those permissions to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd749aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "runtime_response = agentcore_control_client.get_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "runtime_role = runtime_response['roleArn']\n",
    "\n",
    "policies_to_add = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"GetResourceAPIKey\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock-agentcore:GetResourceApiKey\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"SecretManager\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"secretsmanager:GetSecretValue\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "iam_client = boto3.client(\n",
    "    'iam',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "response = iam_client.put_role_policy(\n",
    "    PolicyDocument=json.dumps(policies_to_add),\n",
    "    PolicyName=\"outbound_policies\",\n",
    "    RoleName=runtime_role.split(\"/\")[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bcd3e",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8628e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252820b1",
   "metadata": {},
   "source": [
    "## Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload\n",
    "\n",
    "![deploy](images/invoke.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_response = agentcore_runtime.invoke({\"prompt\": \"Hello\"}, user_id=\"userid_1234567890\")\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b2f1b0",
   "metadata": {},
   "source": [
    "## Processing invocation results\n",
    "We can now process our invocation results to include it in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104b31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489029ea",
   "metadata": {},
   "source": [
    "## Invoking AgentCore Runtime with boto3\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 invoke_agent_runtime method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ddd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    runtimeUserId=\"userid_1234567890\",\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"How much is 2X2?\"})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        if line:\n",
    "            line = line.decode(\"utf-8\")\n",
    "            if line.startswith(\"data: \"):\n",
    "                line = line[6:]\n",
    "                logger.info(line)\n",
    "                content.append(line)\n",
    "    display(Markdown(\"\\n\".join(content)))\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e7141",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ccb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=runtime_role.split(\"/\")[1],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=runtime_role.split(\"/\")[1],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=runtime_role.split(\"/\")[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30c9b4",
   "metadata": {},
   "source": [
    "### Congratulation! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
